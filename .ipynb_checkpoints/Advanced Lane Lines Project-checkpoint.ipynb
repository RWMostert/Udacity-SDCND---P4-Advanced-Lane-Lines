{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import glob\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    plt.imshow(image); plt.axis('off'); plt.show();\n",
    "    \n",
    "def showImages(images):\n",
    "    num_y = int(len(images)/3) + 1\n",
    "    fig = plt.figure(figsize = (10, len(images)*2))\n",
    "    grid = gridspec.GridSpec(num_y, 3, wspace = 0.1, hspace = 0.1, width_ratios=np.ones(shape=(3)), height_ratios=np.ones(shape=(len(images))))\n",
    "    for i, image in enumerate(images):\n",
    "        subp = plt.subplot(grid[i])\n",
    "        subp.imshow(image)\n",
    "        plt.axis('off')\n",
    "        fig.add_subplot(subp)\n",
    "    plt.show();\n",
    "\n",
    "def renderImages(images, k=3):\n",
    "    num_y = int(len(images)/k) + 1\n",
    "    fig = plt.figure(figsize = (3, len(images)/2))\n",
    "    grid = gridspec.GridSpec(num_y, k, wspace = 0., hspace = 0., width_ratios=np.ones(shape=(k)), height_ratios=np.ones(shape=(num_y)))\n",
    "    for i, image in enumerate(images):\n",
    "        subp = plt.subplot(grid[i])\n",
    "        subp.imshow(image)\n",
    "        plt.axis('off')\n",
    "        fig.add_subplot(subp)\n",
    "    \n",
    "    plt.savefig ( \"./latest.png\" )\n",
    "    return(cv2.imread(\"./latest.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image. Thus, objp is just a replicated array of coordinates, and objpoints will be appended with a copy of it every time I successfully detect all chessboard corners in a test image. imgpoints will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dims = (9,6)\n",
    "calibration_images = [mpimg.imread(file) for file in glob.glob(\"./camera_cal/calibration*.jpg\")]\n",
    "grey_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in calibration_images]\n",
    "chessboard_corners = [cv2.findChessboardCorners(image, dims, None) for image in grey_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_with_corners = [cv2.drawChessboardCorners(calibration_images[i], dims, *chessboard_corners[i][::-1]) for i in range(len(calibration_images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((np.prod(dims), 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:dims[0], 0:dims[1]].T.reshape(-1,2)\n",
    "\n",
    "objpoints = [objp for corner_set in chessboard_corners if corner_set[0]]\n",
    "imgpoints = [corner_set[1] for corner_set in chessboard_corners if corner_set[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then used the output objpoints and imgpoints to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function. I applied this distortion correction to the test image using the cv2.undistort() function and obtained this result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calibrate the camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, grey_images[0].shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Undistort the images\n",
    "undistorted_images = [cv2.undistort(image, mtx, dist, None, mtx) for image in calibration_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Perspective Transform function\n",
    "def warp(img, offset = 0.2, bot_width = 0.76, mid_width = 0.08, height_pct = 0.62, bottom_trim = 0.935):\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    \n",
    "    src = np.float32([[w*(0.5 - mid_width/2), h*height_pct],\n",
    "                      [w*(0.5 + mid_width/2), h*height_pct], \n",
    "                      [w*(0.5 + bot_width/2), h*bottom_trim], \n",
    "                      [w*(0.5-bot_width/2),   h*bottom_trim]])\n",
    "    \n",
    "    #offset = .25*w\n",
    "    offset = .2*w\n",
    "    w_offset = .2*w\n",
    "    dst = np.float32([ [offset,   0], \n",
    "                       [w-offset*1.2, 0],\n",
    "                       [w-offset*1.2, h], \n",
    "                       [offset,   h]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, (w, h), flags = cv2.INTER_LINEAR)\n",
    "    return warped, M, M_inv\n",
    "\n",
    "# Define a function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=20, thresh_max=100):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def color_threshold(image, hls_sthresh=(0,255), hsv_sthresh=(0,255), hsv_vthresh=(0,255)):\n",
    "    \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel >= hsv_vthresh[0]) & (v_channel <= hsv_vthresh[1])] = 1\n",
    "    \n",
    "    #hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hsv[:,:,1]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel > hsv_sthresh[0]) & (s_channel <= hsv_sthresh[1])] = 1\n",
    "    \n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s2_channel = hls[:,:,2]\n",
    "    s2_binary = np.zeros_like(s2_channel)\n",
    "    s2_binary[(s2_channel > hls_sthresh[0]) & (s2_channel <= hls_sthresh[1])] = 1\n",
    "    \n",
    "    \"\"\"luv = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "    s2_channel = hls[:,:,2]\n",
    "    s2_binary = np.zeros_like(s2_channel)\n",
    "    s2_binary[(s2_channel > hls_sthresh[0]) & (s2_channel <= hls_sthresh[1])] = 1\"\"\"\n",
    "     \n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_binary == 1) & (v_binary == 1) & (s2_binary == 1)] = 1\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"I detected lane lines from the warped image using a sliding-window-based tracking method \n",
    "(credit: Tutorial Video on P4 by Udacity). This involves firstly summing the vertical pixel\n",
    "values in the image and identifying the 2 peaks in the histogram, which should give an \n",
    "indication of the location of the lane lines.\n",
    "\n",
    "We identify the centers of these peaks and start at the corresponding point in the warped \n",
    "image. We then move up and down, and left and right within certain acceptable limits, \n",
    "identifying the next possible set of pixels that might form part of the lane line.\n",
    "This is done in the method below (credit: P4 Tutorial Video, Udacity)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class tracker():\n",
    "    def __init__(self, Mywindow_width, Mywindow_height, Mymargin, Mysmooth_factor = 15):\n",
    "        \n",
    "        self.recent_centers = []\n",
    "        self.window_width = Mywindow_width\n",
    "        self.window_height = Mywindow_height\n",
    "        self.margin = Mymargin\n",
    "        self.smooth_factor = Mysmooth_factor\n",
    "        \n",
    "    def find_window_centroids(self, warped):\n",
    "        \n",
    "        window_width = self.window_width\n",
    "        window_height = self.window_height\n",
    "        margin = self.margin\n",
    "        \n",
    "        window_centroids = []\n",
    "        window = np.ones(window_width)\n",
    "        \n",
    "        l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "        l_center = np.argmax(np.convolve(window, l_sum)) - window_width/2\n",
    "        r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "        r_center = np.argmax(np.convolve(window, r_sum)) - window_width/2 + int(warped.shape[1]/2)\n",
    "        \n",
    "        window_centroids.append((l_center, r_center))\n",
    "        \n",
    "        for level in range(1, (int)(warped.shape[0]/window_height)):\n",
    "            image_layer = np.sum(warped[int(warped.shape[0] - (level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            \n",
    "            offset = window_width/2\n",
    "            l_min_index = int(max(l_center + offset - margin, 0))\n",
    "            l_max_index = int(min(l_center + offset + margin, warped.shape[1]))\n",
    "            l_center = np.argmax(conv_signal[l_min_index:l_max_index]) + l_min_index - offset\n",
    "            \n",
    "            r_min_index = int(max(r_center + offset - margin, 0))\n",
    "            r_max_index = int(min(r_center + offset + margin, warped.shape[1]))\n",
    "            r_center = np.argmax(conv_signal[r_min_index: r_max_index]) + r_min_index - offset\n",
    "            \n",
    "            window_centroids.append((l_center, r_center))\n",
    "            \n",
    "        self.recent_centers.append(window_centroids)\n",
    "        \n",
    "        return np.average(self.recent_centers[-self.smooth_factor:], axis = 0)\n",
    "    \n",
    "    def detect_lines(self, warped):\n",
    "        \n",
    "        window_centroids = self.find_window_centroids (warped)\n",
    "\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        leftx = []\n",
    "        rightx = []\n",
    "\n",
    "        for level in range(0, len(window_centroids)):\n",
    "\n",
    "            leftx.append(window_centroids[level][0])\n",
    "            rightx.append(window_centroids[level][1])\n",
    "\n",
    "            l_mask = window_mask(self.window_width, self.window_height, warped, window_centroids[level][0], level)\n",
    "            r_mask = window_mask(self.window_width, self.window_height, warped, window_centroids[level][1], level)\n",
    "\n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        template = np.array(r_points + l_points, np.uint8)\n",
    "        zero_channel = np.zeros_like(template)\n",
    "        template = np.array(cv2.merge((zero_channel, template, zero_channel)), np.uint8)\n",
    "        warpage = np.array(cv2.merge((warped, warped, warped)), np.uint8)\n",
    "        detected_lanes = cv2.addWeighted(warpage, 1, template, 0.5, 0.0)\n",
    "        \n",
    "        return detected_lanes, leftx, rightx\n",
    "        \n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0] - (level + 1)*height):int(img_ref.shape[0] - level*height), max(0, int(center-width)):min(int(center+width), img_ref.shape[1])] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lane_fitter():\n",
    "    def __init__(self):\n",
    "        self.previous_left_MSE = float('inf')\n",
    "        self.previous_right_MSE = float('inf')\n",
    "        self.previous_left_poly = np.zeros(shape=(3))\n",
    "        self.previous_right_poly = np.zeros(shape=(3))\n",
    "        self.previous_7_left_lanes = []\n",
    "        self.previous_7_right_lanes = []\n",
    "        \n",
    "    def fit_lanes(self, current_image, window_width, window_height, leftx, rightx):\n",
    "        if len(self.previous_7_left_lanes) > 9:\n",
    "            self.previous_7_left_lanes = self.previous_7_left_lanes[-9:]\n",
    "        if len(self.previous_7_right_lanes) > 9:\n",
    "            self.previous_7_right_lanes = self.previous_7_right_lanes[-9:]\n",
    "            \n",
    "        #Next, I fit a polynomial to the curve:\n",
    "            \n",
    "        yvals = range(0, current_image.shape[0])\n",
    "        res_yvals = np.arange(current_image.shape[0] - (window_height/2), 0, -window_height)\n",
    "\n",
    "        left_fit, left_res, _, _, _ = np.polyfit(res_yvals, leftx, 2, full=True)\n",
    "        right_fit, right_res, _, _, _ = np.polyfit(res_yvals, rightx, 2, full=True)\n",
    "        \n",
    "        self.previous_7_left_lanes.append(left_fit)\n",
    "        self.previous_7_right_lanes.append(right_fit)\n",
    "        \n",
    "        left_fit = np.average(self.previous_7_left_lanes, axis = 0)\n",
    "        right_fit = np.average(self.previous_7_right_lanes, axis = 0)\n",
    "        \n",
    "        #I used the MSE of the fit to inform a weighted average across successive frames.\n",
    "        \"\"\"\n",
    "        MSE = np.mean(np.square(left_res[1:] - right_res[1:]))\n",
    "        \n",
    "        #Bayesian informing\n",
    "        k = MSE/(MSE + self.previous_left_MSE)\n",
    "        left_fit = k*self.previous_left_poly + (1-k)*left_fit\n",
    "\n",
    "        k = MSE/(MSE + self.previous_right_MSE)\n",
    "        right_fit = k*self.previous_right_poly + (1-k)*right_fit\n",
    "\n",
    "        if self.previous_right_MSE < float('inf'):\n",
    "            self.previous_right_MSE = k*self.previous_right_MSE + (1-k)*MSE\n",
    "        else:\n",
    "            self.previous_right_MSE = MSE   \n",
    "        self.previous_right_poly = right_fit\n",
    "\n",
    "        if self.previous_left_MSE < float('inf'):\n",
    "            self.previous_left_MSE = k*self.previous_left_MSE + (1-k)*MSE\n",
    "        else:\n",
    "            self.previous_left_MSE = MSE   \n",
    "        self.previous_left_poly = left_fit\"\"\"\n",
    "\n",
    "        left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "        left_fitx = np.array(left_fitx, np.int32)\n",
    "\n",
    "        right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "        right_fitx = np.array(right_fitx, np.int32)\n",
    "\n",
    "        left_lane = np.array(list(zip(np.concatenate((left_fitx - window_width/2, left_fitx[::-1] + window_width/2), axis = 0), np.concatenate((yvals, yvals[::-1]), axis = 0))), np.int32)\n",
    "        right_lane = np.array(list(zip(np.concatenate((right_fitx - window_width/2, right_fitx[::-1] + window_width/2), axis = 0), np.concatenate((yvals, yvals[::-1]), axis = 0))), np.int32)\n",
    "        inner_lane = np.array(list(zip(np.concatenate((left_fitx + window_width/2, right_fitx[::-1] - window_width/2), axis=0), np.concatenate((yvals, yvals[::-1]), axis = 0))), np.int32)\n",
    "        \n",
    "        #Assuming the lane is about 30 meters long and 3.7 meters wide:\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/720 # meters per pixel in x dimension\n",
    "\n",
    "        # Firstly I fit a second order polynomial (curve) to the left lane. I then used this fitted curve to calculate the angle of the left lane line's curvature. \n",
    "        \n",
    "        corner_curve = np.polyfit(x = np.array(res_yvals, np.float32)*ym_per_pix, \n",
    "                                  y = np.array(leftx, np.float32)*xm_per_pix, \n",
    "                                  deg = 2)\n",
    "        #curve_radians = ((1 + (2*corner_curve[0]*np.max(yvals[-1]*ym_per_pix + corner_curve[1])**2)**1.5) / np.absolute(2*corner_curve[0])\n",
    "        curve_radians = ((1 + (2*corner_curve[0]*np.max(yvals)*ym_per_pix + corner_curve[1])**2)**1.5) / np.absolute(2*corner_curve[0])\n",
    "\n",
    "        camera_center = (left_fitx[-1] + right_fitx[-1])/2\n",
    "        center_diff = (camera_center-current_image.shape[1]/2)*xm_per_pix\n",
    "        \n",
    "        side_pos = 'left'\n",
    "        if center_diff <= 0:\n",
    "            side_pos = \"right\"\n",
    "    \n",
    "        return left_lane, inner_lane, right_lane, curve_radians, center_diff, side_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_road_lanes(image, left_lane, inner_lane, right_lane, M_inv):\n",
    "    road = np.zeros_like(image)\n",
    "    road_bg = np.zeros_like(image)\n",
    "    \n",
    "    cv2.fillPoly(road, [left_lane], color=[255,0,0])\n",
    "    cv2.fillPoly(road, [right_lane], color=[0,0,255])\n",
    "    cv2.fillPoly(road, [inner_lane], color=[0,0,255])\n",
    "    cv2.fillPoly(road_bg, [left_lane], color = [255, 255, 255])\n",
    "    cv2.fillPoly(road_bg, [right_lane], color = [255, 255, 255])\n",
    "    \n",
    "    road_warped = cv2.warpPerspective(road, M_inv, (image.shape[1], image.shape[0]), flags = cv2.INTER_LINEAR)\n",
    "    road_warped_bg = cv2.warpPerspective(road_bg, M_inv, (image.shape[1], image.shape[0]), flags = cv2.INTER_LINEAR)\n",
    "    \n",
    "    base = cv2.addWeighted(image, 1.0, road_warped_bg, -1.0, 0.0)\n",
    "    result = cv2.addWeighted(base, 1.0, road_warped, 1.0, 0.0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#I used a combination of color and gradient thresholds to generate a binary image\"\n",
    "\n",
    "\n",
    "def process_LUV(image):\n",
    "    luv = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "    yellow_mask = cv2.inRange(luv, np.array([140,110,120]), np.array([230, 130, 255]))\n",
    "    yellow_lane = cv2.bitwise_and(luv,luv, mask= yellow_mask)\n",
    "    \n",
    "    white_mask = cv2.inRange(luv, np.array([200,0,100]), np.array([255, 130, 220]))\n",
    "    color_mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    return color_mask\n",
    "\n",
    "\"\"\"hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    hls_l = hls[:,:,1]\n",
    "    gradx_mask = abs_sobel_thresh(hls_l, orient='x', thresh_max=225, thresh_min=50)\n",
    "    grady_mask = abs_sobel_thresh(hls_l, orient='y', thresh_max=225, thresh_min=50)\n",
    "    grad_mask_1 = np.copy(cv2.bitwise_or(gradx_mask, grady_mask))\n",
    "    \n",
    "    hls_s = hls[:,:,2]\n",
    "    gradx_mask = abs_sobel_thresh(hls_s, orient='x', thresh_max=225, thresh_min=50)\n",
    "    grady_mask = abs_sobel_thresh(hls_s, orient='y', thresh_max=225, thresh_min=50)\n",
    "    grad_mask_2 = np.copy(cv2.bitwise_or(gradx_mask, grady_mask))\n",
    "    \n",
    "    sobel = cv2.GaussianBlur(cv2.bitwise_or(grad_mask_1, grad_mask_2), (25, 25), 0)\n",
    "    \n",
    "    white_color_mask = cv2.inRange(hsv, (20, 0, 180), (255, 80, 255))\n",
    "    yellow_color_mask = cv2.inRange(hsv, (0, 100, 100), (50, 255, 255))\n",
    "    c_binary = cv2.bitwise_or(yellow_color_mask, white_color_mask)\"\"\"\n",
    "\n",
    "def apply_masks(img):\n",
    "    \n",
    "    color_mask = process_LUV(img)\n",
    "    \n",
    "    preprocessedImage = np.zeros_like(img[:,:,0])\n",
    "\n",
    "    gradx_mask = abs_sobel_thresh(img, orient='x', thresh_max=225, thresh_min=25)\n",
    "    grady_mask = abs_sobel_thresh(img, orient='y', thresh_max=225, thresh_min=50)\n",
    "\n",
    "    mag_th = mag_thresh(img, sobel_kernel=9, mag_thresh=(50, 250))\n",
    "    dir_th = dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    white_color_mask = color_threshold(img, hls_sthresh = (88, 255), hsv_sthresh=(0, 70), hsv_vthresh=(160, 255))\n",
    "    yellow_color_mask = color_threshold(img, hls_sthresh = (88, 190), hsv_vthresh=(100, 255))\n",
    "\n",
    "    c_binary = cv2.bitwise_or(yellow_color_mask, white_color_mask)\n",
    "\n",
    "    preprocessedImage[((gradx_mask == 1) & (grady_mask == 1))  | (color_mask==255) | ((yellow_color_mask == 1) | (white_color_mask == 1)) & (mag_th == 1) & (dir_th == 1)] = 255\n",
    "    \n",
    "    return preprocessedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_lane_fitter = lane_fitter()\n",
    "\n",
    "def reset_lane_fitter():\n",
    "    global current_lane_fitter\n",
    "    current_lane_fitter = lane_fitter()\n",
    "        \n",
    "def map_lane(img):\n",
    "    global lane_fitter\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    preprocessedImage = apply_masks(img)\n",
    "    \n",
    "    warped, M, M_inv = warp(preprocessedImage, bot_width =0.6, height_pct=0.628)\n",
    "\n",
    "    window_width = 35\n",
    "    window_height = 80\n",
    "    curve_centers = tracker(Mywindow_width = 45, Mywindow_height = 80, Mymargin = 40, Mysmooth_factor = 100)\n",
    "\n",
    "    detected_lanes, leftx, rightx = curve_centers.detect_lines(warped)\n",
    "\n",
    "    left_lane, inner_lane, right_lane, curve_radians, center_diff, side_pos = current_lane_fitter.fit_lanes(warped, window_width, window_height, leftx, rightx)\n",
    "\n",
    "    result = draw_road_lanes(img, left_lane, inner_lane, right_lane, M_inv)\n",
    "\n",
    "    cv2.putText(result, 'Radius of Curvature: ' + str(round(curve_radians, 3)) + '(m)', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    cv2.putText(result, str(abs(round(center_diff, 3))) + 'm ' + side_pos + ' of the center', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    return preprocessedImage, warped, detected_lanes, result\n",
    "\n",
    "def process_4_images(image):\n",
    "    preprocessImage, warped, detected_lanes, result = map_lane(image)\n",
    "    #preprocessImage = map_lane(image)\n",
    "    vis_left = np.concatenate((cv2.cvtColor(preprocessImage,cv2.COLOR_GRAY2RGB), detected_lanes), axis=0)\n",
    "    vis_right = np.concatenate((cv2.cvtColor(warped,cv2.COLOR_GRAY2RGB), result), axis=0)\n",
    "    vis = np.concatenate((vis_left, vis_right), axis=1)\n",
    "    return vis\n",
    "\n",
    "def process_result(image):\n",
    "    preprocessImage, warped, detected_lanes, result = map_lane(image)\n",
    "    #preprocessImage = map_lane(image)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/audio/io/readers.py:110: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.nchannels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MoviePy: building video file project_video_output.mp4\n",
      "----------------------------------------\n",
      "\n",
      "Writing video into project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:53: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:56: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "\n",
      "  0%|          | 0/121 [00:00<?, ?it/s]\u001b[A/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:53: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:56: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "\n",
      "  1%|          | 1/121 [00:00<00:59,  2.01it/s]\u001b[A\n",
      "  2%|▏         | 2/121 [00:01<01:06,  1.80it/s]\u001b[A\n",
      "  2%|▏         | 3/121 [00:01<01:02,  1.88it/s]\u001b[A\n",
      "  3%|▎         | 4/121 [00:02<00:59,  1.98it/s]\u001b[A\n",
      "  4%|▍         | 5/121 [00:02<00:55,  2.08it/s]\u001b[A\n",
      "  5%|▍         | 6/121 [00:02<00:53,  2.15it/s]\u001b[A\n",
      "  6%|▌         | 7/121 [00:03<00:50,  2.25it/s]\u001b[A\n",
      "  7%|▋         | 8/121 [00:03<00:49,  2.29it/s]\u001b[A\n",
      "  7%|▋         | 9/121 [00:04<00:48,  2.29it/s]\u001b[A\n",
      "  8%|▊         | 10/121 [00:04<00:50,  2.21it/s]\u001b[A\n",
      "  9%|▉         | 11/121 [00:05<00:48,  2.25it/s]\u001b[A\n",
      " 10%|▉         | 12/121 [00:05<00:50,  2.17it/s]\u001b[A\n",
      " 11%|█         | 13/121 [00:06<00:47,  2.25it/s]\u001b[A\n",
      " 12%|█▏        | 14/121 [00:06<00:46,  2.31it/s]\u001b[A\n",
      " 12%|█▏        | 15/121 [00:06<00:46,  2.30it/s]\u001b[A\n",
      " 13%|█▎        | 16/121 [00:07<00:45,  2.33it/s]\u001b[A\n",
      " 14%|█▍        | 17/121 [00:07<00:43,  2.37it/s]\u001b[A\n",
      " 15%|█▍        | 18/121 [00:08<00:43,  2.37it/s]\u001b[A\n",
      " 16%|█▌        | 19/121 [00:08<00:43,  2.36it/s]\u001b[A\n",
      " 17%|█▋        | 20/121 [00:08<00:43,  2.34it/s]\u001b[A\n",
      " 17%|█▋        | 21/121 [00:09<00:42,  2.35it/s]\u001b[A\n",
      " 18%|█▊        | 22/121 [00:09<00:43,  2.29it/s]\u001b[A\n",
      " 19%|█▉        | 23/121 [00:10<00:42,  2.29it/s]\u001b[A\n",
      " 20%|█▉        | 24/121 [00:10<00:41,  2.32it/s]\u001b[A\n",
      " 21%|██        | 25/121 [00:11<00:41,  2.29it/s]\u001b[A\n",
      " 21%|██▏       | 26/121 [00:11<00:41,  2.31it/s]\u001b[A\n",
      " 22%|██▏       | 27/121 [00:12<00:40,  2.33it/s]\u001b[A\n",
      " 23%|██▎       | 28/121 [00:12<00:39,  2.38it/s]\u001b[A\n",
      " 24%|██▍       | 29/121 [00:12<00:38,  2.40it/s]\u001b[A\n",
      " 25%|██▍       | 30/121 [00:13<00:37,  2.41it/s]\u001b[A\n",
      " 26%|██▌       | 31/121 [00:13<00:37,  2.43it/s]\u001b[A\n",
      " 26%|██▋       | 32/121 [00:14<00:36,  2.41it/s]\u001b[A\n",
      " 27%|██▋       | 33/121 [00:14<00:40,  2.17it/s]\u001b[A\n",
      " 28%|██▊       | 34/121 [00:15<00:44,  1.94it/s]\u001b[A\n",
      " 29%|██▉       | 35/121 [00:15<00:42,  2.03it/s]\u001b[A\n",
      " 30%|██▉       | 36/121 [00:16<00:40,  2.10it/s]\u001b[A\n",
      " 31%|███       | 37/121 [00:16<00:38,  2.19it/s]\u001b[A\n",
      " 31%|███▏      | 38/121 [00:16<00:36,  2.25it/s]\u001b[A\n",
      " 32%|███▏      | 39/121 [00:17<00:35,  2.29it/s]\u001b[A\n",
      " 33%|███▎      | 40/121 [00:17<00:34,  2.36it/s]\u001b[A\n",
      " 34%|███▍      | 41/121 [00:18<00:33,  2.39it/s]\u001b[A\n",
      " 35%|███▍      | 42/121 [00:18<00:32,  2.42it/s]\u001b[A\n",
      " 36%|███▌      | 43/121 [00:19<00:32,  2.41it/s]\u001b[A\n",
      " 36%|███▋      | 44/121 [00:19<00:32,  2.40it/s]\u001b[A\n",
      " 37%|███▋      | 45/121 [00:19<00:31,  2.41it/s]\u001b[A\n",
      " 38%|███▊      | 46/121 [00:20<00:31,  2.40it/s]\u001b[A\n",
      " 39%|███▉      | 47/121 [00:20<00:30,  2.40it/s]\u001b[A\n",
      " 40%|███▉      | 48/121 [00:21<00:31,  2.34it/s]\u001b[A\n",
      " 40%|████      | 49/121 [00:21<00:30,  2.33it/s]\u001b[A\n",
      " 41%|████▏     | 50/121 [00:22<00:30,  2.30it/s]\u001b[A\n",
      " 42%|████▏     | 51/121 [00:22<00:30,  2.29it/s]\u001b[A\n",
      " 43%|████▎     | 52/121 [00:22<00:30,  2.23it/s]\u001b[A\n",
      " 44%|████▍     | 53/121 [00:23<00:31,  2.17it/s]\u001b[A\n",
      " 45%|████▍     | 54/121 [00:23<00:30,  2.23it/s]\u001b[A\n",
      " 45%|████▌     | 55/121 [00:24<00:29,  2.23it/s]\u001b[A\n",
      " 46%|████▋     | 56/121 [00:24<00:28,  2.27it/s]\u001b[A\n",
      " 47%|████▋     | 57/121 [00:25<00:27,  2.32it/s]\u001b[A\n",
      " 48%|████▊     | 58/121 [00:25<00:27,  2.25it/s]\u001b[A\n",
      " 49%|████▉     | 59/121 [00:26<00:28,  2.17it/s]\u001b[A\n",
      " 50%|████▉     | 60/121 [00:26<00:29,  2.08it/s]\u001b[A\n",
      " 50%|█████     | 61/121 [00:27<00:29,  2.04it/s]\u001b[A\n",
      " 51%|█████     | 62/121 [00:27<00:27,  2.11it/s]\u001b[A\n",
      " 52%|█████▏    | 63/121 [00:27<00:26,  2.19it/s]\u001b[A\n",
      " 53%|█████▎    | 64/121 [00:28<00:25,  2.23it/s]\u001b[A\n",
      " 54%|█████▎    | 65/121 [00:28<00:24,  2.27it/s]\u001b[A\n",
      " 55%|█████▍    | 66/121 [00:29<00:23,  2.30it/s]\u001b[A\n",
      " 55%|█████▌    | 67/121 [00:29<00:23,  2.35it/s]\u001b[A\n",
      " 56%|█████▌    | 68/121 [00:30<00:22,  2.32it/s]\u001b[A\n",
      " 57%|█████▋    | 69/121 [00:30<00:22,  2.30it/s]\u001b[A\n",
      " 58%|█████▊    | 70/121 [00:31<00:22,  2.27it/s]\u001b[A\n",
      " 59%|█████▊    | 71/121 [00:31<00:22,  2.27it/s]\u001b[A\n",
      " 60%|█████▉    | 72/121 [00:31<00:22,  2.20it/s]\u001b[A\n",
      " 60%|██████    | 73/121 [00:32<00:22,  2.15it/s]\u001b[A\n",
      " 61%|██████    | 74/121 [00:32<00:21,  2.17it/s]\u001b[A\n",
      " 62%|██████▏   | 75/121 [00:33<00:21,  2.16it/s]\u001b[A\n",
      " 63%|██████▎   | 76/121 [00:33<00:20,  2.19it/s]\u001b[A\n",
      " 64%|██████▎   | 77/121 [00:34<00:19,  2.25it/s]\u001b[A\n",
      " 64%|██████▍   | 78/121 [00:34<00:18,  2.28it/s]\u001b[A\n",
      " 65%|██████▌   | 79/121 [00:35<00:18,  2.31it/s]\u001b[A\n",
      " 66%|██████▌   | 80/121 [00:35<00:17,  2.33it/s]\u001b[A\n",
      " 67%|██████▋   | 81/121 [00:35<00:17,  2.34it/s]\u001b[A\n",
      " 68%|██████▊   | 82/121 [00:36<00:16,  2.30it/s]\u001b[A\n",
      " 69%|██████▊   | 83/121 [00:36<00:17,  2.23it/s]\u001b[A\n",
      " 69%|██████▉   | 84/121 [00:37<00:18,  2.02it/s]\u001b[A\n",
      " 70%|███████   | 85/121 [00:37<00:17,  2.04it/s]\u001b[A\n",
      " 71%|███████   | 86/121 [00:38<00:16,  2.09it/s]\u001b[A\n",
      " 72%|███████▏  | 87/121 [00:38<00:15,  2.13it/s]\u001b[A\n",
      " 73%|███████▎  | 88/121 [00:39<00:15,  2.16it/s]\u001b[A\n",
      " 74%|███████▎  | 89/121 [00:39<00:14,  2.22it/s]\u001b[A\n",
      " 74%|███████▍  | 90/121 [00:40<00:13,  2.30it/s]\u001b[A\n",
      " 75%|███████▌  | 91/121 [00:40<00:14,  2.14it/s]\u001b[A\n",
      " 76%|███████▌  | 92/121 [00:41<00:14,  1.97it/s]\u001b[A\n",
      " 77%|███████▋  | 93/121 [00:41<00:14,  1.94it/s]\u001b[A\n",
      " 78%|███████▊  | 94/121 [00:42<00:13,  2.00it/s]\u001b[A\n",
      " 79%|███████▊  | 95/121 [00:42<00:12,  2.08it/s]\u001b[A\n",
      " 79%|███████▉  | 96/121 [00:43<00:11,  2.12it/s]\u001b[A\n",
      " 80%|████████  | 97/121 [00:43<00:11,  2.18it/s]\u001b[A\n",
      " 81%|████████  | 98/121 [00:43<00:10,  2.24it/s]\u001b[A\n",
      " 82%|████████▏ | 99/121 [00:44<00:09,  2.26it/s]\u001b[A\n",
      " 83%|████████▎ | 100/121 [00:44<00:09,  2.22it/s]\u001b[A\n",
      " 83%|████████▎ | 101/121 [00:45<00:08,  2.29it/s]\u001b[A\n",
      " 84%|████████▍ | 102/121 [00:45<00:08,  2.29it/s]\u001b[A\n",
      " 85%|████████▌ | 103/121 [00:46<00:07,  2.28it/s]\u001b[A\n",
      " 86%|████████▌ | 104/121 [00:46<00:07,  2.27it/s]\u001b[A\n",
      " 87%|████████▋ | 105/121 [00:47<00:07,  2.19it/s]\u001b[A\n",
      " 88%|████████▊ | 106/121 [00:47<00:07,  2.03it/s]\u001b[A\n",
      " 88%|████████▊ | 107/121 [00:48<00:06,  2.09it/s]\u001b[A\n",
      " 89%|████████▉ | 108/121 [00:48<00:06,  2.14it/s]\u001b[A\n",
      " 90%|█████████ | 109/121 [00:48<00:05,  2.21it/s]\u001b[A\n",
      " 91%|█████████ | 110/121 [00:49<00:04,  2.29it/s]\u001b[A\n",
      " 92%|█████████▏| 111/121 [00:49<00:04,  2.36it/s]\u001b[A\n",
      " 93%|█████████▎| 112/121 [00:50<00:03,  2.38it/s]\u001b[A\n",
      " 93%|█████████▎| 113/121 [00:50<00:03,  2.38it/s]\u001b[A\n",
      " 94%|█████████▍| 114/121 [00:50<00:02,  2.39it/s]\u001b[A\n",
      " 95%|█████████▌| 115/121 [00:51<00:02,  2.42it/s]\u001b[A\n",
      " 96%|█████████▌| 116/121 [00:51<00:02,  2.38it/s]\u001b[A\n",
      " 97%|█████████▋| 117/121 [00:52<00:01,  2.36it/s]\u001b[A\n",
      " 98%|█████████▊| 118/121 [00:52<00:01,  2.38it/s]\u001b[A\n",
      " 98%|█████████▊| 119/121 [00:53<00:00,  2.35it/s]\u001b[A\n",
      " 99%|█████████▉| 120/121 [00:53<00:00,  2.28it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing video in project_video_output.mp4 !\n",
      "Your video is ready !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/audio/io/readers.py:110: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.nchannels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MoviePy: building video file project_video_output_show_pipeline.mp4\n",
      "----------------------------------------\n",
      "\n",
      "Writing video into project_video_output_show_pipeline.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:53: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:56: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "\n",
      "  0%|          | 0/1210 [00:00<?, ?it/s]\u001b[A/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:53: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/Rayno/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:56: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "\n",
      "  0%|          | 1/1210 [00:00<10:26,  1.93it/s]\u001b[A\n",
      "  0%|          | 2/1210 [00:01<10:38,  1.89it/s]\u001b[A\n",
      "  0%|          | 3/1210 [00:02<13:40,  1.47it/s]\u001b[A\n",
      "  0%|          | 4/1210 [00:02<12:43,  1.58it/s]\u001b[A\n",
      "  0%|          | 5/1210 [00:03<11:59,  1.67it/s]\u001b[A\n",
      "  0%|          | 6/1210 [00:03<11:32,  1.74it/s]\u001b[A\n",
      "  1%|          | 7/1210 [00:04<11:35,  1.73it/s]\u001b[A\n",
      "  1%|          | 8/1210 [00:04<11:25,  1.75it/s]\u001b[A\n",
      "  1%|          | 9/1210 [00:05<11:27,  1.75it/s]\u001b[A\n",
      "  1%|          | 10/1210 [00:05<11:15,  1.78it/s]\u001b[A\n",
      "  1%|          | 11/1210 [00:06<10:52,  1.84it/s]\u001b[A\n",
      "  1%|          | 12/1210 [00:06<10:41,  1.87it/s]\u001b[A\n",
      "  1%|          | 13/1210 [00:07<11:18,  1.76it/s]\u001b[A\n",
      "  1%|          | 14/1210 [00:08<11:03,  1.80it/s]\u001b[A\n",
      "  1%|          | 15/1210 [00:08<11:02,  1.80it/s]\u001b[A\n",
      "  1%|▏         | 16/1210 [00:09<11:12,  1.78it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5731a8125892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mclip2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.subclip(20, 30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvideo_clip2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_4_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mvideo_clip2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutput_video\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_show_pipeline.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-159>\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose)\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose)\u001b[0m\n\u001b[1;32m    313\u001b[0m                            \u001b[0mwrite_logfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrite_logfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                            \u001b[0maudiofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudiofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                            verbose=verbose)\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     for t,frame in clip.iter_frames(progress_bar=True, with_times=True,\n\u001b[0;32m--> 184\u001b[0;31m                                     fps=fps):\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;31m# Update and print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mwith_times\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Coming soon: smart error handling for debugging at this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Rayno/anaconda3/lib/python3.5/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \"\"\"\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;31m#--------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-99069fd542cc>\u001b[0m in \u001b[0;36mprocess_4_images\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_4_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpreprocessImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_lane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#preprocessImage = map_lane(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mvis_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_GRAY2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_lanes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-99069fd542cc>\u001b[0m in \u001b[0;36mmap_lane\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpreprocessedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessedImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbot_width\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_pct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.625\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-81271ce0f112>\u001b[0m in \u001b[0;36mapply_masks\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mpreprocessedImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mgradx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_sobel_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mgrady_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_sobel_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f8a685ec3590>\u001b[0m in \u001b[0;36mabs_sobel_thresh\u001b[0;34m(img, orient, thresh_min, thresh_max)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mabs_sobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mabs_sobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Output_video = 'project_video_output'\n",
    "Input_video = 'project_video.mp4'\n",
    "\n",
    "reset_lane_fitter()\n",
    "\n",
    "clip1 =  VideoFileClip(Input_video).subclip(23, 28)\n",
    "video_clip = clip1.fl_image(process_result)\n",
    "video_clip.write_videofile(Output_video + \".mp4\", audio = False)\n",
    "\n",
    "\n",
    "reset_lane_fitter()\n",
    "\n",
    "clip2 =  VideoFileClip(Input_video)#.subclip(20, 30)\n",
    "video_clip2 = clip2.fl_image(process_4_images)\n",
    "video_clip2.write_videofile(Output_video + \"_show_pipeline.mp4\", audio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
